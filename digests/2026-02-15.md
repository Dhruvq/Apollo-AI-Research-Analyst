# Apollo AI Research Digest — 2026-02-15

*25 most impactful cs.AI papers*

## 1. Adaptive Collaboration of Arena-Based Argumentative LLMs for Explainable and Contestable Legal Reasoning

**Authors:** Hoang-Loc Cao, Phuc Ho, Truong Thanh Hung Nguyen et al.  
**Submitted:** 2026-02-21  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.18916v1](https://arxiv.org/abs/2602.18916v1)

> The paper presents a novel neuro-symbolic framework addressing a critical gap in LLM legal reasoning – explainability and contestability – with strong empirical results and potential for broader impact in AI safety and legal tech.

Legal reasoning requires not only high accuracy but also the ability to justify decisions through verifiable and contestable arguments. However, existing Large Language Model (LLM) approaches, such as Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG), often produce unstructured explanations that lack a formal mechanism for verification or user intervention. To address this limitation, we propose Adaptive Collaboration of Argumentative LLMs (ACAL), a neuro-symbolic framework that in...

---

## 2. Aurora: Neuro-Symbolic AI Driven Advising Agent

**Authors:** Lorena Amanda Quincoso Lugones, Christopher Kverne, Nityam Sharadkumar Bhimani et al.  
**Submitted:** 2026-02-20  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17999v1](https://arxiv.org/abs/2602.17999v1)

> The paper addresses a significant problem with a novel neuro-symbolic approach, demonstrates strong methodological rigor through a structured evaluation, and has broad implications for improving access to higher education advising.

Academic advising in higher education is under severe strain, with advisor-to-student ratios commonly exceeding 300:1. These structural bottlenecks limit timely access to guidance, increase the risk of delayed graduation, and contribute to inequities in student support. We introduce Aurora, a modular neuro-symbolic advising agent that unifies retrieval-augmented generation (RAG), symbolic reasoning, and normalized curricular databases to deliver policy-compliant, verifiable recommendations at sc...

---

## 3. Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial

**Authors:** Yousef Emami, Hao Zhou, Radha Reddy et al.  
**Submitted:** 2026-02-23  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19534v1](https://arxiv.org/abs/2602.19534v1)

> This survey paper addresses a highly relevant and emerging intersection of LLMs and UAVs, offering a comprehensive overview and framework that could significantly guide future research and development in the field.

Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and con...

---

## 4. El Agente Gráfico: Structured Execution Graphs for Scientific Agents

**Authors:** Jiaru Bai, Abdulrahman Aldossary, Thomas Swanick et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17902v1](https://arxiv.org/abs/2602.17902v1)

> The paper addresses a critical challenge in LLM-driven scientific workflows – robustness and auditability – with a novel approach using structured execution graphs and typed object mapping, demonstrating strong potential for impact in the field.

Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making ...

---

## 5. AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence

**Authors:** Geunbin Yu  
**Submitted:** 2026-02-18  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16873v1](https://arxiv.org/abs/2602.16873v1)

> The paper addresses a timely and important problem – moving beyond model selection to orchestration as LLMs converge – with a rigorous framework, novel algorithms, and validation across diverse tasks, suggesting significant potential impact on how LLM systems are built and deployed.

As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dyna...

---

## 6. IR$^3$: Contrastive Inverse Reinforcement Learning for Interpretable Detection and Mitigation of Reward Hacking

**Authors:** Mohammad Beigi, Ming Jin, Junshan Zhang et al.  
**Submitted:** 2026-02-23  
**Impact Score:** 12 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.19416v1](https://arxiv.org/abs/2602.19416v1)

> This paper addresses a critical and emerging problem in RLHF (reward hacking) with a novel framework (IR3) combining contrastive IRL, interpretability techniques, and targeted mitigation strategies, demonstrating strong potential for impact on the field of LLM alignment and safety.

Reinforcement Learning from Human Feedback (RLHF) enables powerful LLM alignment but can introduce reward hacking - models exploit spurious correlations in proxy rewards without genuine alignment. Compounding this, the objectives internalized during RLHF remain opaque, making hacking behaviors difficult to detect or correct. We introduce IR3 (Interpretable Reward Reconstruction and Rectification), a framework that reverse-engineers, interprets, and surgically repairs the implicit objectives driv...

---

## 7. KNIGHT: Knowledge Graph-Driven Multiple-Choice Question Generation with Adaptive Hardness Calibration

**Authors:** Mohammad Amanlou, Erfan Shafiee Moghaddam, Yasaman Amou Jafari et al.  
**Submitted:** 2026-02-23  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.20135v1](https://arxiv.org/abs/2602.20135v1)

> The paper addresses a critical bottleneck in LLM evaluation with a novel knowledge graph approach to MCQ generation, offering good methodological rigor and broader implications for efficient and controllable dataset creation.

With the rise of large language models (LLMs), they have become instrumental in applications such as Retrieval-Augmented Generation (RAG). Yet evaluating these systems remains bottlenecked by the time and cost of building specialized assessment datasets. We introduce KNIGHT, an LLM-based, knowledge-graph-driven framework for generating multiple-choice question (MCQ) datasets from external sources. KNIGHT constructs a topic-specific knowledge graph, a structured and parsimonious summary of entiti...

---

## 8. MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems

**Authors:** Jin Jia, Zhiling Deng, Zhuangbin Chen et al.  
**Submitted:** 2026-02-23  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19843v1](https://arxiv.org/abs/2602.19843v1)

> This paper addresses a critical and emerging problem in LLM-based MAS reliability with a novel fault injection framework and insightful tiered analysis, offering significant implications for building robust multi-agent systems.

As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallucinations, misinterpreted instructions, and reasoning drift) that propagate silently without raising runtime exceptions. Prevailing evaluation approaches, which measure only end-to-end task success, offer limited insight...

---

## 9. Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model

**Authors:** Louth Bin Rawshan, Zhuoyu Wang, Brian Y Lim  
**Submitted:** 2026-02-23  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19620v1](https://arxiv.org/abs/2602.19620v1)

> The paper presents a novel cognitive model (CoXAM) to compare XAI techniques, grounded in a user study and validated against human decision-making, offering significant implications for the design and evaluation of explainable AI systems.

Rules and Weights are popular XAI techniques for explaining AI decisions. Yet, it remains unclear how to choose between them, lacking a cognitive framework to compare their interpretability. In an elicitation user study on forward and counterfactual decision tasks, we identified 7 reasoning strategies of interpreting three XAI Schemas - weights, rules, and their hybrid. To analyze their capabilities, we propose CoXAM, a Cognitive XAI-Adaptive Model with shared memory representation to encode ins...

---

## 10. Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations

**Authors:** Dongming Jiang, Yi Li, Songtao Wei et al.  
**Submitted:** 2026-02-22  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19320v1](https://arxiv.org/abs/2602.19320v1)

> This paper provides a crucial, comprehensive survey and analysis of a rapidly evolving field (agentic memory) identifying key limitations and offering a structured taxonomy, which will likely guide future research and development efforts.

Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. T...

---

## 11. Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering

**Authors:** Maryam Amirizaniani, Alireza Salemi, Hamed Zamani  
**Submitted:** 2026-02-22  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19317v1](https://arxiv.org/abs/2602.19317v1)

> The paper addresses a crucial challenge in personalized QA with a novel reinforcement learning approach to adaptive retrieval and reasoning, demonstrating strong empirical results on a relevant benchmark, suggesting significant potential impact.

Personalization in Question Answering (QA) requires answers that are both accurate and aligned with users' background, preferences, and historical context. Existing state-of-the-art methods primarily rely on retrieval-augmented generation (RAG) solutions that construct personal context by retrieving relevant items from the user's profile. Existing methods use the user's query directly to retrieve personal documents, and such strategies often lead to surface-level personalization. We propose PR2 ...

---

## 12. Topology of Reasoning: Retrieved Cell Complex-Augmented Generation for Textual Graph Question Answering

**Authors:** Sen Zhao, Lincheng Zhou, Yue Chen et al.  
**Submitted:** 2026-02-22  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19240v1](https://arxiv.org/abs/2602.19240v1)

> The paper addresses a significant limitation in existing RAG methods for graph question answering by incorporating topological information, offering a novel approach with potentially broad implications for reasoning over complex relational data.

Retrieval-Augmented Generation (RAG) enhances the reasoning ability of Large Language Models (LLMs) by dynamically integrating external knowledge, thereby mitigating hallucinations and strengthening contextual grounding for structured data such as graphs. Nevertheless, most existing RAG variants for textual graphs concentrate on low-dimensional structures -- treating nodes as entities (0-dimensional) and edges or paths as pairwise or sequential relations (1-dimensional), but overlook cycles, whi...

---

## 13. Beyond Behavioural Trade-Offs: Mechanistic Tracing of Pain-Pleasure Decisions in an LLM

**Authors:** Francesca Bianco, Derek Shiller  
**Submitted:** 2026-02-22  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19159v1](https://arxiv.org/abs/2602.19159v1)

> This paper combines behavioral observations with rigorous mechanistic interpretability techniques to understand how LLMs process valence, offering a strong contribution to the field of AI alignment and interpretability with potentially broad implications for understanding decision-making in these models.

Prior behavioural work suggests that some LLMs alter choices when options are framed as causing pain or pleasure, and that such deviations can scale with stated intensity. To bridge behavioural evidence (what the model does) with mechanistic interpretability (what computations support it), we investigate how valence-related information is represented and where it is causally used inside a transformer. Using Gemma-2-9B-it and a minimalist decision task modelled on prior work, we (i) map represent...

---

## 14. Give Users the Wheel: Towards Promptable Recommendation Paradigm

**Authors:** Fuyuan Lyu, Chenglin Luo, Qiyuan Zhang et al.  
**Submitted:** 2026-02-21  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.18929v1](https://arxiv.org/abs/2602.18929v1)

> This paper addresses a significant limitation of current recommendation systems by effectively integrating LLMs for prompt-based control without sacrificing efficiency or collaborative filtering, demonstrating strong novelty and potential for broad impact.

Conventional sequential recommendation models have achieved remarkable success in mining implicit behavioral patterns. However, these architectures remain structurally blind to explicit user intent: they struggle to adapt when a user's immediate goal (e.g., expressed via a natural language prompt) deviates from their historical habits. While Large Language Models (LLMs) offer the semantic reasoning to interpret such intent, existing integration paradigms force a dilemma: LLM-as-a-recommender par...

---

## 15. RPU -- A Reasoning Processing Unit

**Authors:** Matthew Adiletta, Gu-Yeon Wei, David Brooks  
**Submitted:** 2026-02-20  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.18568v1](https://arxiv.org/abs/2602.18568v1)

> The paper addresses a critical bottleneck in LLM inference with a novel architecture (RPU) and specific optimizations (HBM-CO, chiplet design, decoupled pipelines) showing significant performance gains, suggesting strong potential impact on future LLM hardware.

Large language model (LLM) inference performance is increasingly bottlenecked by the memory wall. While GPUs continue to scale raw compute throughput, they struggle to deliver scalable performance for memory bandwidth bound workloads. This challenge is amplified by emerging reasoning LLM applications, where long output sequences, low arithmetic intensity, and tight latency constraints demand significantly higher memory bandwidth. As a result, system utilization drops and energy per inference ris...

---

## 16. CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications

**Authors:** Victoria Blake, Mathew Miller, Jamie Novak et al.  
**Submitted:** 2026-02-20  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17949v1](https://arxiv.org/abs/2602.17949v1)

> The paper addresses a significant bottleneck in clinical NLP (concept set curation) with a novel GraphRAG approach, demonstrates strong performance against a gold standard, and has clear implications for improving downstream task accuracy and efficiency.

Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Met...

---

## 17. Alignment in Time: Peak-Aware Orchestration for Long-Horizon Agentic Systems

**Authors:** Hanjing Shi, Dominic DiFranzo  
**Submitted:** 2026-02-20  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17910v1](https://arxiv.org/abs/2602.17910v1)

> The paper addresses a crucial and relatively unexplored aspect of AI alignment – sustained reliability in long-horizon agents – with a novel, practical approach (APEMO) and strong empirical validation, suggesting significant potential impact.

Traditional AI alignment primarily focuses on individual model outputs; however, autonomous agents in long-horizon workflows require sustained reliability across entire interaction trajectories. We introduce APEMO (Affect-aware Peak-End Modulation for Orchestration), a runtime scheduling layer that optimizes computational allocation under fixed budgets by operationalizing temporal-affective signals. Instead of modifying model weights, APEMO detects trajectory instability through behavioral proxi...

---

## 18. Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability

**Authors:** Shashank Aggarwal, Ram Vikas Mishra, Amit Awekar  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17544v1](https://arxiv.org/abs/2602.17544v1)

> This paper introduces valuable new metrics (reusability and verifiability) for evaluating CoT reasoning beyond simple accuracy, highlighting a critical gap in current evaluation practices and offering potentially broad implications for multi-agent LLM systems.

In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusa...

---

## 19. Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation

**Authors:** Dun Yuan, Hao Zhou, Xue Liu et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17529v1](https://arxiv.org/abs/2602.17529v1)

> The paper addresses a practical problem (LLM application in telecom) with a well-defined and potentially impactful solution (KG-RAG) demonstrating significant performance gains, suggesting strong research impact and applicability.

Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom operations.To address these limitations, this work introduces KG-RAG-a novel framework that integrates knowle...

---

## 20. SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework

**Authors:** Rong Fu, Zijian Zhang, Wenxin Zhang et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17330v1](https://arxiv.org/abs/2602.17330v1)

> The paper addresses significant bottlenecks in immune repertoire analysis with a novel, well-integrated pipeline demonstrating both performance gains and fairness considerations, suggesting strong potential for impact in the field.

Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that addresses these challenges by combining antigen-aware, near-subquadratic retrieval with GPU-accelerated affinity kernels, learned multimodal fusion, and fairness-constrained clustering. The system empl...

---

## 21. IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents

**Authors:** Seoyoung Lee, Seobin Yoon, Seongbeen Lee et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17049v1](https://arxiv.org/abs/2602.17049v1)

> The paper addresses a significant challenge in computer-use agents – long-horizon planning and intent alignment – with a novel multi-agent framework and strong empirical results, suggesting substantial potential impact on the field.

Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate ...

---

## 22. MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation

**Authors:** Iman Ahmadi, Mehrshad Taji, Arad Mahdinezhad Kashani et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16898v2](https://arxiv.org/abs/2602.16898v2)

> This paper presents a novel multi-agent framework leveraging LLMs and VLMs for robust robotic manipulation with closed-loop feedback, demonstrating strong potential for advancing the field beyond current open-loop approaches and offering practical improvements in dynamic environments.

Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.MALLVi present a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi gener...

---

## 23. References Improve LLM Alignment in Non-Verifiable Domains

**Authors:** Kejian Shi, Yixin Liu, Peifeng Wang et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16802v1](https://arxiv.org/abs/2602.16802v1)

> This paper addresses a significant challenge in LLM alignment – applying RLHF to non-verifiable domains – with a novel and effective approach using reference-guided LLM evaluators, demonstrating strong results comparable to existing methods and offering broader implications for self-improvement techniques.

While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridge this gap by serving as soft "verifiers". First, we design evaluation protocols that enhance LLM-based evaluators for LLM alignment using reference outputs. Through comprehensive experiments, we show...

---

## 24. Policy Compiler for Secure Agentic Systems

**Authors:** Nils Palumbo, Sarthak Choudhary, Jihye Choi et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16708v2](https://arxiv.org/abs/2602.16708v2)

> This paper addresses a critical security gap in LLM-based agentic systems with a novel approach to deterministic policy enforcement using dependency graphs and a Datalog-derived language, offering significant implications for real-world deployments.

LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.
  Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture...

---

## 25. SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation

**Authors:** Jaid Monwar Chowdhury, Chi-An Fu, Reyhaneh Jabbarvand  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16671v1](https://arxiv.org/abs/2602.16671v1)

> SPARC addresses a significant challenge in software testing with a novel neuro-symbolic approach, demonstrating strong empirical results and offering broader implications for reliable LLM-based code generation.

Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in n...

---
