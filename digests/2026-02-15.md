# Apollo AI Research Digest — 2026-02-15

*25 most impactful cs.AI papers*

## 1. Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling

**Authors:** Ji Li, Jing Xia, Mingyi Li et al.  
**Submitted:** 2026-02-17  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15513v1](https://arxiv.org/abs/2602.15513v1)

> The paper addresses a significant challenge in embodied AI with a novel memory modeling approach that combines episodic and semantic memory, demonstrating strong empirical results and offering potential for broader impact in robotics and agent-based systems.

Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. O...

---

## 2. Panini: Continual Learning in Token Space via Structured Memory

**Authors:** Shreyas Rajesh, Pavan Holur, Mehmet Yigit Turali et al.  
**Submitted:** 2026-02-16  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15156v1](https://arxiv.org/abs/2602.15156v1)

> This paper addresses a significant challenge in LLM deployment (continual learning and RAG efficiency) with a novel approach (GSW) that shows promise for improving reasoning and reducing computational cost, potentially impacting how LLMs interact with evolving information.

Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject...

---

## 3. AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence

**Authors:** Geunbin Yu  
**Submitted:** 2026-02-18  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16873v1](https://arxiv.org/abs/2602.16873v1)

> The paper addresses a timely and important problem – moving beyond model selection to orchestration as LLMs converge – with a rigorous framework, novel algorithms, and strong empirical validation, suggesting significant potential impact on how multi-agent systems are designed and deployed.

As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dyna...

---

## 4. LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio

**Authors:** Naveen Vakada, Kartik Hegde, Arvind Krishna Sridhar et al.  
**Submitted:** 2026-02-16  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.14612v1](https://arxiv.org/abs/2602.14612v1)

> This paper addresses a significant challenge in long-form audio understanding with a novel RAG approach grounded in acoustic events, demonstrating strong methodological rigor through a synthetic benchmark and edge-cloud deployment, suggesting substantial potential impact.

Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long-audio question answering remains difficult due to context-length limits. We introduce LongAudio-RAG (LA-RAG), a hybrid framework that grounds Large Language Model (LLM) outputs in retrieved, timestam...

---

## 5. Retrieval Collapses When AI Pollutes the Web

**Authors:** Hongyeon Yu, Dongchan Kim, Young-Bum Kim  
**Submitted:** 2026-02-18  
**Impact Score:** 12 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.16136v1](https://arxiv.org/abs/2602.16136v1)

> This paper identifies a critical and novel threat to information retrieval systems – 'Retrieval Collapse' – with strong empirical evidence and significant implications for the future of search and RAG, particularly as AI-generated content continues to grow.

The rapid proliferation of AI-generated content on the Web presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG) systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates search results, eroding source diversity, and (2) low-quality or adversarial content infiltrates the retrieval ...

---

## 6. Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections

**Authors:** Xianglin Yang, Yufei He, Shuo Ji et al.  
**Submitted:** 2026-02-17  
**Impact Score:** 12 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.15654v1](https://arxiv.org/abs/2602.15654v1)

> This paper identifies a novel and significant security vulnerability in a rapidly developing area (LLM agents) with a well-defined attack framework and broad implications for the trustworthiness of these systems.

Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the age...

---

## 7. Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability

**Authors:** Shashank Aggarwal, Ram Vikas Mishra, Amit Awekar  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17544v1](https://arxiv.org/abs/2602.17544v1)

> This paper introduces valuable new metrics (reusability and verifiability) for evaluating CoT reasoning beyond simple accuracy, highlighting a critical gap in current evaluation practices and offering potentially broad implications for LLM development and multi-agent systems.

In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusa...

---

## 8. Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation

**Authors:** Dun Yuan, Hao Zhou, Xue Liu et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17529v1](https://arxiv.org/abs/2602.17529v1)

> The paper addresses a practical problem (LLM application in telecom) with a well-defined and potentially impactful solution (KG-RAG) demonstrating significant performance gains, suggesting strong research impact and applicability.

Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom operations.To address these limitations, this work introduces KG-RAG-a novel framework that integrates knowle...

---

## 9. SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework

**Authors:** Rong Fu, Zijian Zhang, Wenxin Zhang et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17330v1](https://arxiv.org/abs/2602.17330v1)

> The paper addresses significant bottlenecks in immune repertoire analysis with a novel, well-integrated pipeline demonstrating both performance gains and fairness considerations, suggesting strong potential for impact in the field.

Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that addresses these challenges by combining antigen-aware, near-subquadratic retrieval with GPU-accelerated affinity kernels, learned multimodal fusion, and fairness-constrained clustering. The system empl...

---

## 10. IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents

**Authors:** Seoyoung Lee, Seobin Yoon, Seongbeen Lee et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17049v1](https://arxiv.org/abs/2602.17049v1)

> The paper addresses a critical challenge in computer-use agents – long-horizon planning and intent alignment – with a novel multi-agent framework and strong empirical results, suggesting significant potential impact on the field of AI and human-computer interaction.

Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate ...

---

## 11. References Improve LLM Alignment in Non-Verifiable Domains

**Authors:** Kejian Shi, Yixin Liu, Peifeng Wang et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16802v1](https://arxiv.org/abs/2602.16802v1)

> This paper addresses a significant challenge in LLM alignment – applying RLHF to non-verifiable domains – with a novel and effective approach using reference-guided LLM evaluators, demonstrating strong results comparable to existing methods and offering broader implications for self-improvement techniques.

While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridge this gap by serving as soft "verifiers". First, we design evaluation protocols that enhance LLM-based evaluators for LLM alignment using reference outputs. Through comprehensive experiments, we show...

---

## 12. Policy Compiler for Secure Agentic Systems

**Authors:** Nils Palumbo, Sarthak Choudhary, Jihye Choi et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16708v2](https://arxiv.org/abs/2602.16708v2)

> This paper addresses a critical security gap in LLM-based agentic systems with a novel approach to deterministic policy enforcement using dependency graphs and a Datalog-derived language, offering significant implications for real-world deployments.

LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.
  Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture...

---

## 13. SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation

**Authors:** Jaid Monwar Chowdhury, Chi-An Fu, Reyhaneh Jabbarvand  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16671v1](https://arxiv.org/abs/2602.16671v1)

> SPARC addresses a significant challenge in software testing with a novel neuro-symbolic approach, demonstrating strong empirical results and offering broader implications for reliable LLM-based code generation.

Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in n...

---

## 14. Retrieval Augmented Generation of Literature-derived Polymer Knowledge: The Example of a Biodegradable Polymer Expert System

**Authors:** Sonakshi Gupta, Akhlak Mahmood, Wei Xiong et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16650v1](https://arxiv.org/abs/2602.16650v1)

> This paper addresses a significant bottleneck in materials science (knowledge extraction from literature) with a novel application of RAG using both vector and graph-based approaches, demonstrating strong potential for accelerating polymer research and design.

Polymer literature contains a large and growing body of experimental knowledge, yet much of it is buried in unstructured text and inconsistent terminology, making systematic retrieval and reasoning difficult. Existing tools typically extract narrow, study-specific facts in isolation, failing to preserve the cross-study context required to answer broader scientific questions. Retrieval-augmented generation (RAG) offers a promising way to overcome this limitation by combining large language models...

---

## 15. Avey-B

**Authors:** Devang Acharya, Mohammad Hammoud  
**Submitted:** 2026-02-17  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15814v1](https://arxiv.org/abs/2602.15814v1)

> The paper presents a novel attention-free alternative to Transformers with strong empirical results and potential for efficient scaling, addressing a key limitation of current industrial NLP models.

Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradi...

---

## 16. RUVA: Personalized Transparent On-Device Graph Reasoning

**Authors:** Gabriele Conte, Alessio Mattiace, Gianni Carmosino et al.  
**Submitted:** 2026-02-17  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15553v1](https://arxiv.org/abs/2602.15553v1)

> This paper addresses a critical limitation of current Personal AI systems (lack of transparency and true data deletion) with a novel graph-based approach, offering strong potential for impact on privacy, accountability, and user control.

The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box...

---

## 17. EAA: Automating materials characterization with vision language model agents

**Authors:** Ming Du, Yanqi Luo, Srutarshi Banerjee et al.  
**Submitted:** 2026-02-17  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15294v1](https://arxiv.org/abs/2602.15294v1)

> This paper presents a novel application of vision-language models to automate complex materials characterization workflows, with strong potential to broaden access and improve efficiency in scientific experimentation, and the MCP compatibility is a significant step towards interoperability.

We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM que...

---

## 18. Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems

**Authors:** Furkan Mumcu, Yasin Yilmaz  
**Submitted:** 2026-02-16  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.14471v1](https://arxiv.org/abs/2602.14471v1)

> The paper addresses a critical challenge in multi-agent LLM systems with a novel game-theoretic framework and provides both theoretical guarantees and empirical validation, suggesting strong potential for impact in the field of AI safety and multi-agent systems.

Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weighted Alignment (SWA), a game-theoretic framework that modifies inference-time decision making by interpolating between an agent's private objective and an estimate of group welfare via a social weight $λ\in[0,1]$. In a sh...

---

## 19. Differentially Private Retrieval-Augmented Generation

**Authors:** Tingting Tang, James Flemings, Yongqin Wang et al.  
**Submitted:** 2026-02-16  
**Impact Score:** 11 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.14374v1](https://arxiv.org/abs/2602.14374v1)

> This paper addresses a critical privacy concern in a popular framework (RAG) with a novel algorithm (DP-KSA) that balances privacy guarantees with utility, demonstrating strong potential for impact in sensitive application areas.

Retrieval-augmented generation (RAG) is a widely used framework for reducing hallucinations in large language models (LLMs) on domain-specific tasks by retrieving relevant documents from a database to support accurate responses. However, when the database contains sensitive corpora, such as medical records or legal documents, RAG poses serious privacy risks by potentially exposing private information through its outputs. Prior work has demonstrated that one can practically craft adversarial prom...

---

## 20. AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing

**Authors:** Jianda Du, Youran Sun, Haizhao Yang  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.17607v1](https://arxiv.org/abs/2602.17607v1)

> This paper presents a novel, PDE-agnostic framework for automated solver design with strong methodological rigor (multi-agent system, self-verification) and potentially broad implications for democratizing scientific computing by reducing the need for specialized expertise.

PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited interpretability. We introduce \texttt{AutoNumerics}, a multi-agent framework that autonomously designs, implements, debugs, and verifies numerical solvers for general PDEs directly from natural language d...

---

## 21. Universal Fine-Grained Symmetry Inference and Enforcement for Rigorous Crystal Structure Prediction

**Authors:** Shi Yin, Jinming Mu, Xudong Zhu et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 11 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.17176v1](https://arxiv.org/abs/2602.17176v1)

> This paper presents a novel approach to crystal structure prediction by directly inferring and enforcing symmetry using large language models and constrained optimization, potentially overcoming limitations of existing methods and enabling the discovery of new materials.

Crystal structure prediction (CSP), which aims to predict the three-dimensional atomic arrangement of a crystal from its composition, is central to materials discovery and mechanistic understanding. Existing deep learning models often treat crystallographic symmetry only as a soft heuristic or rely on space group and Wyckoff templates retrieved from known structures, which limits both physical fidelity and the ability to discover genuinely new material structures. In contrast to retrieval-based ...

---

## 22. Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents

**Authors:** Arnold Cartagena, Ariane Teixeira  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.16943v1](https://arxiv.org/abs/2602.16943v1)

> This paper addresses a critical and previously underexplored safety gap in LLM agents, employs a rigorous and comprehensive evaluation framework (GAP benchmark), and has broad implications for the safe deployment of increasingly powerful AI systems.

Large language models deployed as agents increasingly interact with external systems through tool calls--actions with real-world consequences that text outputs alone do not carry. Safety evaluations, however, overwhelmingly measure text-level refusal behavior, leaving a critical question unanswered: does alignment that suppresses harmful text also suppress harmful actions? We introduce the GAP benchmark, a systematic evaluation framework that measures divergence between text-level safety and too...

---

## 23. Xray-Visual Models: Scaling Vision models on Industry Scale Data

**Authors:** Shlok Mishra, Tsung-Yu Lin, Linda Wang et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.16918v1](https://arxiv.org/abs/2602.16918v1)

> The paper's scale of data, novel training pipeline, strong performance across benchmarks, and exploration of LLM integration suggest high potential for impact in the vision and multimodal learning fields.

We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data curation pipelines that incorporate balancing and noise suppression strategies to maximize semantic diversity while minimizing label noise. We introduce a three-stage training pipeline that combines sel...

---

## 24. Fast and Scalable Analytical Diffusion

**Authors:** Xinyi Shang, Peng Sun, Jingyu Lin et al.  
**Submitted:** 2026-02-18  
**Impact Score:** 11 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.16498v1](https://arxiv.org/abs/2602.16498v1)

> This paper addresses a significant scalability issue in analytical diffusion models with a novel theoretical justification and a practical, training-free solution, potentially broadening the applicability of these models to larger datasets and impacting future research in efficient generative modeling.

Analytical diffusion models offer a mathematically transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean. However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study addressing this scalability bottleneck. We challenge the prevailing assumption that the entire training data is...

---

## 25. Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination

**Authors:** Amir Hosseinian, MohammadReza Zare Shahneh, Umer Mansoor et al.  
**Submitted:** 2026-02-17  
**Impact Score:** 11 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.16050v1](https://arxiv.org/abs/2602.16050v1)

> This paper demonstrates a significant performance improvement over state-of-the-art LLMs in a challenging subspecialty domain, highlighting the value of curated knowledge and structured reasoning, which has strong implications for clinical decision support and medical education.

Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corp...

---
