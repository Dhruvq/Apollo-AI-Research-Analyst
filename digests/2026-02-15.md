# Apollo AI Research Digest — 2026-02-15

*25 most impactful cs.AI papers*

## 1. Voxtral Realtime

**Authors:** Alexander H. Liu, Andy Ehrenberg, Andy Lo et al.  
**Submitted:** 2026-02-11  
**Impact Score:** 16 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.11298v2](https://arxiv.org/abs/2602.11298v2)

> This paper presents a novel, end-to-end streaming ASR model achieving competitive performance with offline systems at very low latency, with a large multilingual dataset and open-source release, indicating high potential impact.

We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. ...

---

## 2. Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment

**Authors:** Jing Zhao, Ting Zhen, Junwei bao et al.  
**Submitted:** 2026-02-14  
**Impact Score:** 14 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13575v1](https://arxiv.org/abs/2602.13575v1)

> The paper presents a novel co-evolutionary approach to LLM alignment with strong theoretical grounding and empirical validation showing significant improvements over existing methods, suggesting high potential impact.

Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win...

---

## 3. Adaptive Collaboration of Arena-Based Argumentative LLMs for Explainable and Contestable Legal Reasoning

**Authors:** Hoang-Loc Cao, Phuc Ho, Truong Thanh Hung Nguyen et al.  
**Submitted:** 2026-02-21  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.18916v1](https://arxiv.org/abs/2602.18916v1)

> The paper presents a novel neuro-symbolic framework addressing a critical gap in LLM legal reasoning – explainability and contestability – with strong empirical results and a clear path for human interaction, suggesting significant research impact.

Legal reasoning requires not only high accuracy but also the ability to justify decisions through verifiable and contestable arguments. However, existing Large Language Model (LLM) approaches, such as Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG), often produce unstructured explanations that lack a formal mechanism for verification or user intervention. To address this limitation, we propose Adaptive Collaboration of Argumentative LLMs (ACAL), a neuro-symbolic framework that in...

---

## 4. Aurora: Neuro-Symbolic AI Driven Advising Agent

**Authors:** Lorena Amanda Quincoso Lugones, Christopher Kverne, Nityam Sharadkumar Bhimani et al.  
**Submitted:** 2026-02-20  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17999v1](https://arxiv.org/abs/2602.17999v1)

> The paper addresses a significant problem with a novel neuro-symbolic approach, demonstrates strong performance improvements over a baseline, and has potential for broad impact in higher education by scaling personalized advising.

Academic advising in higher education is under severe strain, with advisor-to-student ratios commonly exceeding 300:1. These structural bottlenecks limit timely access to guidance, increase the risk of delayed graduation, and contribute to inequities in student support. We introduce Aurora, a modular neuro-symbolic advising agent that unifies retrieval-augmented generation (RAG), symbolic reasoning, and normalized curricular databases to deliver policy-compliant, verifiable recommendations at sc...

---

## 5. Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling

**Authors:** Ji Li, Jing Xia, Mingyi Li et al.  
**Submitted:** 2026-02-17  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15513v1](https://arxiv.org/abs/2602.15513v1)

> The paper addresses a significant challenge in embodied AI with a novel memory modeling approach that combines episodic and semantic memory, demonstrating strong empirical results and offering potential for broader impact in robotics and agent-based systems.

Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. O...

---

## 6. Panini: Continual Learning in Token Space via Structured Memory

**Authors:** Shreyas Rajesh, Pavan Holur, Mehmet Yigit Turali et al.  
**Submitted:** 2026-02-16  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15156v1](https://arxiv.org/abs/2602.15156v1)

> The paper addresses a significant challenge in LLM deployment (continual learning and RAG efficiency) with a novel approach using structured semantic memory, demonstrating strong potential for improving reasoning and reducing computational cost.

Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject...

---

## 7. Guided Collaboration in Heterogeneous LLM-Based Multi-Agent Systems via Entropy-Based Understanding Assessment and Experience Retrieval

**Authors:** Linlin Wang, Tianqing Zhu, Laiqiao Qin et al.  
**Submitted:** 2026-02-14  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13639v1](https://arxiv.org/abs/2602.13639v1)

> The paper addresses a critical challenge in heterogeneous multi-agent systems (cognitive mismatch) with a novel entropy-based guidance framework, supported by counterintuitive experimental findings and offering potentially broad implications for improving collaborative AI systems.

With recent breakthroughs in large language models (LLMs) for reasoning, planning, and complex task generation, artificial intelligence systems are transitioning from isolated single-agent architectures to multi-agent systems with collaborative intelligence. However, in heterogeneous multi-agent systems (HMAS), capability differences among agents give rise to consistent cognitive problems, where strong and weak models fail to contribute effectively. We define the collaboration as a strong-weak s...

---

## 8. Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts

**Authors:** Chen Yang, Guangyue Peng, Jiaying Zhu et al.  
**Submitted:** 2026-02-13  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13367v1](https://arxiv.org/abs/2602.13367v1)

> The paper presents a novel, high-performing small language model with impressive capabilities across multiple domains, potentially impacting research on efficient and versatile AI systems, though broader adoption will depend on community validation.

We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling, ensuring high-quality, human-aligned responses. For code generation, we design complexi...

---

## 9. CacheMind: From Miss Rates to Why -- Natural-Language, Trace-Grounded Reasoning for Cache Replacement

**Authors:** Kaushal Mhapsekar, Azam Ghanbari, Bita Aslrousta et al.  
**Submitted:** 2026-02-12  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.12422v1](https://arxiv.org/abs/2602.12422v1)

> This paper presents a novel application of LLMs to a traditionally hardware-focused problem (cache replacement), offering a potentially impactful shift towards more semantic and explainable cache analysis, supported by a new benchmark suite and strong results.

Cache replacement remains a challenging problem in CPU microarchitecture, often addressed using hand-crafted heuristics, limiting cache performance. Cache data analysis requires parsing millions of trace entries with manual filtering, making the process slow and non-interactive. To address this, we introduce CacheMind, a conversational tool that uses Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to enable semantic reasoning over cache traces. Architects can now ask natura...

---

## 10. Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion

**Authors:** Pengcheng Zhou, Haochen Li, Zhiqiang Nie et al.  
**Submitted:** 2026-02-11  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.15895v1](https://arxiv.org/abs/2602.15895v1)

> This paper presents a novel RAG framework (CogitoRAG) inspired by human cognition with a focus on semantic integrity and complex query handling, demonstrating strong potential for improving retrieval accuracy and reducing hallucinations, and the multi-faceted approach suggests broader implications for knowledge representation and retrieval.

Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. Du...

---

## 11. MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval

**Authors:** Xin Zhang, Kailai Yang, Chenyue Li et al.  
**Submitted:** 2026-02-09  
**Impact Score:** 13 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.08369v1](https://arxiv.org/abs/2602.08369v1)

> This paper addresses a significant challenge in LLM agents – the lack of interoperability between different memory paradigms – with a novel and well-designed framework (MemAdapter) demonstrating strong empirical results and offering broader implications for building more flexible and powerful agents.

Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retriev...

---

## 12. The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context

**Authors:** Xiaoyuan Liu, Tian Liang, Dongyang Ma et al.  
**Submitted:** 2026-02-12  
**Impact Score:** 13 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.12108v1](https://arxiv.org/abs/2602.12108v1)

> This paper presents a genuinely novel approach to overcoming context window limitations in LLMs by enabling models to actively manage their own state and memory, with strong empirical results across multiple challenging tasks suggesting significant potential impact.

In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the "wand" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation mo...

---

## 13. AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems

**Authors:** Faouzi El Yagoubi, Ranwa Al Mallah, Godwin Badu-Marfo  
**Submitted:** 2026-02-12  
**Impact Score:** 13 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.11510v1](https://arxiv.org/abs/2602.11510v1)

> This paper addresses a critical and novel privacy vulnerability in emerging multi-agent LLM systems, employs a rigorous full-stack benchmark with a comprehensive taxonomy, and has broad implications for the safe deployment of these systems, making it highly impactful.

Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, to the best of our knowledge the first full-stack benchmark for privacy leakage covering internal channels, spanning 1,000 scenarios across healthcare, finance, legal, and corporate domains, paired wi...

---

## 14. LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation

**Authors:** Zhiling Yan, Dingjie Song, Zhe Fang et al.  
**Submitted:** 2026-02-10  
**Impact Score:** 13 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.10367v1](https://arxiv.org/abs/2602.10367v1)

> This paper addresses critical issues in LLM medical evaluation – contamination and evolving knowledge – with a novel, automated, and rigorous benchmark, promising significant impact on the field's progress and responsible deployment of these models.

The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reas...

---

## 15. Towards Autonomous Mathematics Research

**Authors:** Tony Feng, Trieu H. Trinh, Garrett Bingham et al.  
**Submitted:** 2026-02-10  
**Impact Score:** 13 (LLM: 9/10)  
**arXiv:** [https://arxiv.org/abs/2602.10177v2](https://arxiv.org/abs/2602.10177v2)

> This paper demonstrates a significant leap towards autonomous mathematical research, evidenced by the generation of novel results and collaborative proofs, showcasing high novelty, scope, and potential for broad implications in both AI and mathematics.

Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is pow...

---

## 16. Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial

**Authors:** Yousef Emami, Hao Zhou, Radha Reddy et al.  
**Submitted:** 2026-02-23  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.19534v1](https://arxiv.org/abs/2602.19534v1)

> This survey paper addresses a highly relevant and emerging intersection of LLMs and UAVs, offering a comprehensive overview and framework that could significantly guide future research and development in the field.

Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and con...

---

## 17. El Agente Gráfico: Structured Execution Graphs for Scientific Agents

**Authors:** Jiaru Bai, Abdulrahman Aldossary, Thomas Swanick et al.  
**Submitted:** 2026-02-19  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.17902v1](https://arxiv.org/abs/2602.17902v1)

> The paper addresses a critical challenge in LLM-driven scientific workflows – robustness and auditability – with a novel approach using structured execution graphs and typed objects, demonstrating strong potential for impact in automating complex scientific tasks.

Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making ...

---

## 18. AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence

**Authors:** Geunbin Yu  
**Submitted:** 2026-02-18  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.16873v1](https://arxiv.org/abs/2602.16873v1)

> The paper addresses a timely and important problem – moving beyond model selection to orchestration as LLMs converge – with a rigorous framework, novel algorithms, and strong empirical validation, suggesting significant potential impact on how multi-agent systems are designed and deployed.

As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dyna...

---

## 19. LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio

**Authors:** Naveen Vakada, Kartik Hegde, Arvind Krishna Sridhar et al.  
**Submitted:** 2026-02-16  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.14612v2](https://arxiv.org/abs/2602.14612v2)

> This paper addresses a significant challenge in long-form audio processing with a novel and practical approach (LA-RAG) that combines acoustic event detection with RAG, demonstrating strong potential for impact in areas like surveillance, meeting analysis, and accessibility.

Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long-audio question answering remains difficult due to context-length limits. We introduce LongAudio-RAG (LA-RAG), a hybrid framework that grounds Large Language Model (LLM) outputs in retrieved, timestam...

---

## 20. Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning

**Authors:** Chaeeun Lee, T. Michael Yates, Pasquale Minervini et al.  
**Submitted:** 2026-02-15  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.14160v1](https://arxiv.org/abs/2602.14160v1)

> This paper addresses a critical gap in LLM-based multi-agent systems by focusing on both outcome accuracy *and* process alignment in a high-stakes clinical reasoning task, demonstrating a novel approach with strong empirical results and clear broader implications for reliable AI in healthcare.

Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical real-world case of this is gene-disease validity curation, where experts must determine whether a gene is causally implicated in a disease by synthesising diverse biomedical evidence. We introduce an...

---

## 21. HyMem: Hybrid Memory Architecture with Dynamic Retrieval Scheduling

**Authors:** Xiaochen Zhao, Kaikai Wang, Xiaowen Zhang et al.  
**Submitted:** 2026-02-15  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13933v1](https://arxiv.org/abs/2602.13933v1)

> The paper addresses a critical limitation of LLM agents – long-term memory – with a novel hybrid architecture and dynamic retrieval, showing strong potential for improving performance and efficiency in complex dialogue scenarios.

Large language model (LLM) agents demonstrate strong performance in short-text contexts but often underperform in extended dialogues due to inefficient memory management. Existing approaches face a fundamental trade-off between efficiency and effectiveness: memory compression risks losing critical details required for complex reasoning, while retaining raw text introduces unnecessary computational overhead for simple queries. The crux lies in the limitations of monolithic memory representations ...

---

## 22. PT-RAG: Structure-Fidelity Retrieval-Augmented Generation for Academic Papers

**Authors:** Rui Yu, Tianyi Wang, Ruixia Liu et al.  
**Submitted:** 2026-02-14  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13647v1](https://arxiv.org/abs/2602.13647v1)

> The paper addresses a significant problem in RAG for academic papers – preserving document structure – with a novel approach (PaperTree index and path-guided retrieval) that has the potential to improve performance and efficiency, and the focus on low-entropy retrieval is a strong methodological contribution.

Retrieval-augmented generation (RAG) is increasingly applied to question-answering over long academic papers, where accurate evidence allocation under a fixed token budget is critical. Existing approaches typically flatten academic papers into unstructured chunks during preprocessing, which destroys the native hierarchical structure. This loss forces retrieval to operate in a disordered space, thereby producing fragmented contexts, misallocating tokens to non-evidential regions under finite toke...

---

## 23. LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems

**Authors:** Zhipeng Song, Xiangyu Kong, Xinrui Bao et al.  
**Submitted:** 2026-02-14  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13571v1](https://arxiv.org/abs/2602.13571v1)

> This paper presents a novel, training-free reranking method leveraging LLM confidence scores, addressing a key challenge in RAG systems with strong empirical results on standard benchmarks, suggesting significant potential impact.

Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval and ranking. Although existing rerankers demonstrate effectiveness, they frequently necessitate specialized training, impose substantial computational expenses, and fail to fully exploit the semantic ca...

---

## 24. Mitigating the Safety-utility Trade-off in LLM Alignment via Adaptive Safe Context Learning

**Authors:** Yanbo Wang, Minzheng Wang, Jian Liang et al.  
**Submitted:** 2026-02-14  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.13562v1](https://arxiv.org/abs/2602.13562v1)

> This paper addresses a critical challenge in LLM alignment – the safety-utility trade-off – with a novel framework (ASCL) and a clever optimization technique (IFPO), showing strong potential for improving both safety and reasoning capabilities.

While reasoning models have achieved remarkable success in complex reasoning tasks, their increasing power necessitates stringent safety measures. For safety alignment, the core challenge lies in the inherent trade-off between safety and utility. However, prevailing alignment strategies typically construct CoT training data with explicit safety rules via context distillation. This approach inadvertently limits reasoning capabilities by creating a rigid association between rule memorization and r...

---

## 25. Learning to Remember: End-to-End Training of Memory Agents for Long-Context Reasoning

**Authors:** Kehao Zhang, Shangtong Gui, Sheng Yang et al.  
**Submitted:** 2026-02-13  
**Impact Score:** 12 (LLM: 8/10)  
**arXiv:** [https://arxiv.org/abs/2602.18493v1](https://arxiv.org/abs/2602.18493v1)

> The paper presents a novel end-to-end learning framework for memory agents with a strong focus on dynamic reasoning and a new benchmark, demonstrating significant improvements over existing methods and suggesting broader implications for handling long-context information.

Long-context LLMs and Retrieval-Augmented Generation (RAG) systems process information passively, deferring state tracking, contradiction resolution, and evidence aggregation to query time, which becomes brittle under ultra long streams with frequent updates. We propose the Unified Memory Agent (UMA), an end-to-end reinforcement learning framework that unifies memory operations and question answering within a single policy. UMA maintains a dual memory representation: a compact core summary for g...

---
