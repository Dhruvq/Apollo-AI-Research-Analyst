<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Apollo — AI Research Digest</title>
  <style>
    :root {
      --bg: #0d1117;
      --surface: #161b22;
      --border: #30363d;
      --text: #c9d1d9;
      --muted: #8b949e;
      --accent: #58a6ff;
      --accent-dim: #1f6feb;
      --green: #3fb950;
      --score-high: #3fb950;
      --score-mid: #d29922;
      --score-low: #f85149;
    }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      background: var(--bg);
      color: var(--text);
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
      line-height: 1.6;
      padding: 2rem 1rem;
    }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    .container { max-width: 860px; margin: 0 auto; }

    /* Header */
    header { border-bottom: 1px solid var(--border); padding-bottom: 1.5rem; margin-bottom: 2rem; }
    header .logo { font-size: 1.1rem; color: var(--muted); margin-bottom: 0.5rem; }
    header h1 { font-size: 2rem; font-weight: 700; color: var(--text); }
    header .meta { font-size: 0.85rem; color: var(--muted); margin-top: 0.5rem; }

    /* Archive nav */
    .archive { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 1rem 1.25rem; margin-bottom: 2rem; }
    .archive h2 { font-size: 0.9rem; text-transform: uppercase; letter-spacing: 0.05em; color: var(--muted); margin-bottom: 0.75rem; }
    .archive ul { list-style: none; display: flex; flex-wrap: wrap; gap: 0.5rem; }
    .archive li a {
      display: inline-block;
      background: var(--bg);
      border: 1px solid var(--border);
      border-radius: 4px;
      padding: 0.2rem 0.6rem;
      font-size: 0.8rem;
      color: var(--muted);
    }
    .archive li a:hover { color: var(--accent); border-color: var(--accent-dim); text-decoration: none; }
    .archive li a.current { border-color: var(--accent); color: var(--accent); }

    /* Paper card */
    .paper {
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 1.25rem 1.5rem;
      margin-bottom: 1.25rem;
    }
    .paper-header { display: flex; align-items: flex-start; gap: 1rem; }
    .rank {
      flex-shrink: 0;
      width: 2.2rem;
      height: 2.2rem;
      border-radius: 50%;
      background: var(--accent-dim);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.85rem;
      color: #fff;
    }
    .paper-title a { font-size: 1.05rem; font-weight: 600; color: var(--text); }
    .paper-title a:hover { color: var(--accent); }
    .paper-meta { margin-top: 0.35rem; font-size: 0.8rem; color: var(--muted); }

    .scores { display: flex; gap: 0.6rem; margin: 0.75rem 0; flex-wrap: wrap; }
    .badge {
      font-size: 0.75rem;
      padding: 0.2rem 0.55rem;
      border-radius: 999px;
      border: 1px solid currentColor;
      white-space: nowrap;
    }
    .badge-final { color: var(--accent); }
    .badge-llm-high { color: var(--score-high); }
    .badge-llm-mid  { color: var(--score-mid); }
    .badge-llm-low  { color: var(--score-low); }

    .llm-reason {
      font-size: 0.875rem;
      color: var(--accent);
      font-style: italic;
      margin-bottom: 0.6rem;
      border-left: 3px solid var(--accent-dim);
      padding-left: 0.75rem;
    }
    .abstract {
      font-size: 0.875rem;
      color: var(--muted);
      display: -webkit-box;
      -webkit-line-clamp: 4;
      -webkit-box-orient: vertical;
      overflow: hidden;
    }
    .arxiv-link { display: inline-block; margin-top: 0.75rem; font-size: 0.8rem; }

    footer { margin-top: 3rem; padding-top: 1rem; border-top: 1px solid var(--border); font-size: 0.8rem; color: var(--muted); text-align: center; }
  </style>
</head>
<body>
<div class="container">

  <header>
    <div class="logo">Apollo — Autonomous AI Research Analyst</div>
    <h1>
      Latest Digest
      &mdash; 2026-02-02 to 2026-02-24
    </h1>
    <div class="meta">
      25 papers &bull; 2026-02-02 to 2026-02-24 &bull; Generated 2026-02-24 &bull;
      cs.AI &bull; <a href="https://github.com/Dhruvq/Apollo-AI-Research-Analyst">GitHub</a>
    </div>
  </header>

  

  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">1</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.11298v2" target="_blank" rel="noopener">Voxtral Realtime</a>
        <div class="paper-meta">
          Alexander H. Liu, Andy Ehrenberg, Andy Lo et al.
          &bull; 2026-02-11
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 16</span>
      <span class="badge badge-llm-high">
        Impact: 9/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 1</span>
      
      <span class="badge" style="color: var(--green)">Author boost: +6</span>
      
    </div>

    
    <div class="llm-reason">This paper presents a novel, end-to-end streaming ASR model achieving competitive performance with offline systems at very low latency, with a large multilingual dataset and open-source release, indicating high potential impact.</div>
    

    <div class="abstract">We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.11298v2" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.11298v2
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">2</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13575v1" target="_blank" rel="noopener">Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment</a>
        <div class="paper-meta">
          Jing Zhao, Ting Zhen, Junwei bao et al.
          &bull; 2026-02-14
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 14</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 3</span>
      
      <span class="badge" style="color: var(--green)">Author boost: +3</span>
      
    </div>

    
    <div class="llm-reason">The paper presents a novel co-evolutionary approach to LLM alignment with strong theoretical grounding and empirical validation showing significant improvements over existing methods, suggesting high potential impact.</div>
    

    <div class="abstract">Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win/loss outcomes in pairwise competitions, and (2) implementing Elo-orchestrated opponent selection that provides automatic curriculum learning through temperature-controlled sampling. We ground our approach in PAC learning theory, demonstrating that pairwise comparison achieves superior sample complexity and empirically validate a 4.5x noise reduction compared to absolute scoring approaches. Experimentally, we train a Qwen2.5-7B model using our framework with opponents including Qwen2.5-14B, Qwen2.5-32B, and Qwen3-8B models. Results demonstrate a clear performance hierarchy: point-based methods &lt; static pairwise training &lt; Elo-Evolve across Alpaca Eval 2.0 and MT-Bench, validating the progressive benefits of pairwise comparison and dynamic opponent selection for LLM alignment.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13575v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13575v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">3</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.18916v1" target="_blank" rel="noopener">Adaptive Collaboration of Arena-Based Argumentative LLMs for Explainable and Contestable Legal Reasoning</a>
        <div class="paper-meta">
          Hoang-Loc Cao, Phuc Ho, Truong Thanh Hung Nguyen et al.
          &bull; 2026-02-21
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">The paper presents a novel neuro-symbolic framework addressing a critical gap in LLM legal reasoning – explainability and contestability – with strong empirical results and a clear path for human interaction, suggesting significant research impact.</div>
    

    <div class="abstract">Legal reasoning requires not only high accuracy but also the ability to justify decisions through verifiable and contestable arguments. However, existing Large Language Model (LLM) approaches, such as Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG), often produce unstructured explanations that lack a formal mechanism for verification or user intervention. To address this limitation, we propose Adaptive Collaboration of Argumentative LLMs (ACAL), a neuro-symbolic framework that integrates adaptive multi-agent collaboration with an Arena-based Quantitative Bipolar Argumentation Framework (A-QBAF). ACAL dynamically deploys expert agent teams to construct arguments, employs a clash resolution mechanism to adjudicate conflicting claims, and utilizes uncertainty-aware escalation for borderline cases. Crucially, our framework supports a Human-in-the-Loop (HITL) contestability workflow, enabling users to directly audit and modify the underlying reasoning graph to influence the final judgment. Empirical evaluations on the LegalBench benchmark demonstrate that ACAL outperforms strong baselines across Gemini-2.5-Flash-Lite and Gemini-2.5-Flash architectures, effectively balancing efficient predictive performance with structured transparency and contestability. Our implementation is available at: https://github.com/loc110504/ACAL.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.18916v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.18916v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">4</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.17999v1" target="_blank" rel="noopener">Aurora: Neuro-Symbolic AI Driven Advising Agent</a>
        <div class="paper-meta">
          Lorena Amanda Quincoso Lugones, Christopher Kverne, Nityam Sharadkumar Bhimani et al.
          &bull; 2026-02-20
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a significant problem with a novel neuro-symbolic approach, demonstrates strong performance improvements over a baseline, and has potential for broad impact in higher education by scaling personalized advising.</div>
    

    <div class="abstract">Academic advising in higher education is under severe strain, with advisor-to-student ratios commonly exceeding 300:1. These structural bottlenecks limit timely access to guidance, increase the risk of delayed graduation, and contribute to inequities in student support. We introduce Aurora, a modular neuro-symbolic advising agent that unifies retrieval-augmented generation (RAG), symbolic reasoning, and normalized curricular databases to deliver policy-compliant, verifiable recommendations at scale. Aurora integrates three components: (i) a Boyce-Codd Normal Form (BCNF) catalog schema for consistent program rules, (ii) a Prolog engine for prerequisite and credit enforcement, and (iii) an instruction-tuned large language model for natural-language explanations of its recommendations. To assess performance, we design a structured evaluation suite spanning common and edge-case advising scenarios, including short-term scheduling, long-term roadmapping, skill-aligned pathways, and out-of-scope requests. Across this diverse set, Aurora improves semantic alignment with expert-crafted answers from 0.68 (Raw LLM baseline) to 0.93 (+36%), achieves perfect precision and recall in nearly half of in-scope cases, and consistently produces correct fallbacks for unanswerable prompts. On commodity hardware, Aurora delivers sub-second mean latency (0.71s across 20 queries), approximately 83X faster than a Raw LLM baseline (59.2s). By combining symbolic rigor with neural fluency, Aurora advances a paradigm for accurate, explainable, and scalable AI-driven advising.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.17999v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.17999v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">5</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.15513v1" target="_blank" rel="noopener">Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling</a>
        <div class="paper-meta">
          Ji Li, Jing Xia, Mingyi Li et al.
          &bull; 2026-02-17
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a significant challenge in embodied AI with a novel memory modeling approach that combines episodic and semantic memory, demonstrating strong empirical results and offering potential for broader impact in robotics and agent-based systems.</div>
    

    <div class="abstract">Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.15513v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.15513v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">6</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.15156v1" target="_blank" rel="noopener">Panini: Continual Learning in Token Space via Structured Memory</a>
        <div class="paper-meta">
          Shreyas Rajesh, Pavan Holur, Mehmet Yigit Turali et al.
          &bull; 2026-02-16
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a significant challenge in LLM deployment (continual learning and RAG efficiency) with a novel approach using structured semantic memory, demonstrating strong potential for improving reasoning and reducing computational cost.</div>
    

    <div class="abstract">Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.15156v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.15156v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">7</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13639v1" target="_blank" rel="noopener">Guided Collaboration in Heterogeneous LLM-Based Multi-Agent Systems via Entropy-Based Understanding Assessment and Experience Retrieval</a>
        <div class="paper-meta">
          Linlin Wang, Tianqing Zhu, Laiqiao Qin et al.
          &bull; 2026-02-14
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a critical challenge in heterogeneous multi-agent systems (cognitive mismatch) with a novel entropy-based guidance framework, supported by counterintuitive experimental findings and offering potentially broad implications for improving collaborative AI systems.</div>
    

    <div class="abstract">With recent breakthroughs in large language models (LLMs) for reasoning, planning, and complex task generation, artificial intelligence systems are transitioning from isolated single-agent architectures to multi-agent systems with collaborative intelligence. However, in heterogeneous multi-agent systems (HMAS), capability differences among agents give rise to consistent cognitive problems, where strong and weak models fail to contribute effectively. We define the collaboration as a strong-weak system. Through comprehensive experiments, we disclose a counterintuitive phenomenon in the strong-weak system: a strong-weak collaboration may under-perform weak-weak combinations, revealing that cognitive mismatching are key bottlenecks limiting heterogeneous cooperation. To overcome these challenges, we propose an Entropy-Based Adaptive Guidance Framework that dynamically aligns the guidance with the cognitive state of each agent. The framework quantifies the understanding of weak agents through multi-dimensional entropy metrics - covering expression, uncertainty, structure, coherence, and relevance - and adaptively adjusts the intensity of the guidance at light, moderate and intensive levels. Furthermore, a Retrieval-Augmented Generation (RAG) mechanism is incorporated to retain successful collaboration experiences, enabling both immediate adaptation and long-term learning. Extensive experiments on three benchmark datasets, GSM8K, MBPP, and CVRP demonstrate that our approach consistently enhances the effectiveness and stability of heterogeneous collaboration. The results highlight that adaptive guidance not only mitigates cognitive imbalance but also establishes a scalable pathway toward more robust, cooperative multi-agent intelligence.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13639v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13639v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">8</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13367v1" target="_blank" rel="noopener">Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts</a>
        <div class="paper-meta">
          Chen Yang, Guangyue Peng, Jiaying Zhu et al.
          &bull; 2026-02-13
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 2</span>
      
      <span class="badge" style="color: var(--green)">Author boost: +3</span>
      
    </div>

    
    <div class="llm-reason">The paper presents a novel, high-performing small language model with impressive capabilities across multiple domains, potentially impacting research on efficient and versatile AI systems, though broader adoption will depend on community validation.</div>
    

    <div class="abstract">We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling, ensuring high-quality, human-aligned responses. For code generation, we design complexity-aware rewards in Reinforcement Learning, optimizing both correctness and efficiency. In deep search, we perform complex data synthesis and incorporate turn-level supervision during training. This enables stable long-horizon tool interactions, allowing Nanbeige4.1-3B to reliably execute up to 600 tool-call turns for complex problem-solving. Extensive experimental results show that Nanbeige4.1-3B significantly outperforms prior models of similar scale, such as Nanbeige4-3B-2511 and Qwen3-4B, even achieving superior performance compared to much larger models, such as Qwen3-30B-A3B. Our results demonstrate that small models can achieve both broad competence and strong specialization simultaneously, redefining the potential of 3B parameter models.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13367v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13367v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">9</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.12422v1" target="_blank" rel="noopener">CacheMind: From Miss Rates to Why -- Natural-Language, Trace-Grounded Reasoning for Cache Replacement</a>
        <div class="paper-meta">
          Kaushal Mhapsekar, Azam Ghanbari, Bita Aslrousta et al.
          &bull; 2026-02-12
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">This paper presents a novel application of LLMs to a traditionally hardware-focused problem (cache replacement), offering a potentially impactful shift towards more semantic and explainable cache analysis, supported by a new benchmark suite and strong results.</div>
    

    <div class="abstract">Cache replacement remains a challenging problem in CPU microarchitecture, often addressed using hand-crafted heuristics, limiting cache performance. Cache data analysis requires parsing millions of trace entries with manual filtering, making the process slow and non-interactive. To address this, we introduce CacheMind, a conversational tool that uses Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to enable semantic reasoning over cache traces. Architects can now ask natural language questions like, &#34;Why is the memory access associated with PC X causing more evictions?&#34;, and receive trace-grounded, human-readable answers linked to program semantics for the first time. To evaluate CacheMind, we present CacheMindBench, the first verified benchmark suite for LLM-based reasoning for the cache replacement problem. Using the SIEVE retriever, CacheMind achieves 66.67% on 75 unseen trace-grounded questions and 84.80% on 25 unseen policy-specific reasoning tasks; with RANGER, it achieves 89.33% and 64.80% on the same evaluations. Additionally, with RANGER, CacheMind achieves 100% accuracy on 4 out of 6 categories in the trace-grounded tier of CacheMindBench. Compared to LlamaIndex (10% retrieval success), SIEVE achieves 60% and RANGER achieves 90%, demonstrating that existing Retrieval-Augmented Generation (RAGs) are insufficient for precise, trace-grounded microarchitectural reasoning. We provided four concrete actionable insights derived using CacheMind, wherein bypassing use case improved cache hit rate by 7.66% and speedup by 2.04%, software fix use case gives speedup of 76%, and Mockingjay replacement policy use case gives speedup of 0.7%; showing the utility of CacheMind on non-trivial queries that require a natural-language interface.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.12422v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.12422v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">10</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.15895v1" target="_blank" rel="noopener">Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion</a>
        <div class="paper-meta">
          Pengcheng Zhou, Haochen Li, Zhiqiang Nie et al.
          &bull; 2026-02-11
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">This paper presents a novel RAG framework (CogitoRAG) inspired by human cognition with a focus on semantic integrity and complex query handling, demonstrating strong potential for improving retrieval accuracy and reducing hallucinations, and the multi-faceted approach suggests broader implications for knowledge representation and retrieval.</div>
    

    <div class="abstract">Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. During the offline indexing stage, CogitoRAG first deduces unstructured corpora into gist memory corpora, which are then transformed into a multi-dimensional knowledge graph integrating entities, relational facts, and memory nodes. In the online retrieval stage, the framework handles complex queries via Query Decomposition Module that breaks them into comprehensive sub-queries, mimicking the cognitive decomposition humans employ for complex information. Subsequently, Entity Diffusion Module performs associative retrieval across the graph, guided by structural relevance and an entity-frequency reward mechanism. Furthermore, we propose the CogniRank algorithm, which precisely reranks candidate passages by fusing diffusion-derived scores with semantic similarity. The final evidence is delivered to the generator in a passage-memory pairing format, providing high-density information support. Experimental results across five mainstream QA benchmarks and multi-task generation on GraphBench demonstrate that CogitoRAG significantly outperforms state-of-the-art RAG methods, showcasing superior capabilities in complex knowledge integration and reasoning.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.15895v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.15895v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">11</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.08369v1" target="_blank" rel="noopener">MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval</a>
        <div class="paper-meta">
          Xin Zhang, Kailai Yang, Chenyue Li et al.
          &bull; 2026-02-09
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 5</span>
      
    </div>

    
    <div class="llm-reason">This paper addresses a significant challenge in LLM agents – the lack of interoperability between different memory paradigms – with a novel and well-designed framework (MemAdapter) demonstrating strong empirical results and offering broader implications for building more flexible and powerful agents.</div>
    

    <div class="abstract">Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.08369v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.08369v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">12</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.12108v1" target="_blank" rel="noopener">The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context</a>
        <div class="paper-meta">
          Xiaoyuan Liu, Tian Liang, Dongyang Ma et al.
          &bull; 2026-02-12
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 9/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper presents a genuinely novel approach to overcoming context window limitations in LLMs by enabling models to actively manage their own state and memory, with strong empirical results across multiple challenging tasks suggesting significant potential impact.</div>
    

    <div class="abstract">In the world of Harry Potter, when Dumbledore&#39;s mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the &#34;wand&#34; to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model&#39;s hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM&#39;s effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.12108v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.12108v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">13</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.11510v1" target="_blank" rel="noopener">AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems</a>
        <div class="paper-meta">
          Faouzi El Yagoubi, Ranwa Al Mallah, Godwin Badu-Marfo
          &bull; 2026-02-12
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 9/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper addresses a critical and novel privacy vulnerability in emerging multi-agent LLM systems, employs a rigorous full-stack benchmark with a comprehensive taxonomy, and has broad implications for the safe deployment of these systems, making it highly impactful.</div>
    

    <div class="abstract">Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, to the best of our knowledge the first full-stack benchmark for privacy leakage covering internal channels, spanning 1,000 scenarios across healthcare, finance, legal, and corporate domains, paired with a 32-class attack taxonomy and three-tier detection pipeline. Testing GPT-4o, GPT-4o-mini, Claude 3.5 Sonnet, Mistral Large, and Llama 3.3 70B across 4,979 traces reveals that multi-agent configurations reduce per-channel output leakage (C1: 27.2% vs 43.2% in single-agent) but introduce unmonitored internal channels that raise total system exposure to 68.9% (OR-aggregated across C1, C2, C5). Internal channels account for most of this gap: inter-agent messages (C2) leak at 68.8%, compared to 27.2% on C1 (output channel). This means that output-only audits miss 41.7% of violations. Claude 3.5 Sonnet, which emphasizes safety alignment in its design, achieves the lowest leakage rates on both external (3.3%) and internal (28.1%) channels, suggesting that model-level safety training may transfer to internal channel protection. Across all five models and four domains, the pattern C2 &gt; C1 holds consistently, confirming that inter-agent communication is the primary vulnerability. These findings underscore the need for coordination frameworks that incorporate internal-channel privacy protections and enforce privacy controls on inter-agent communication.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.11510v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.11510v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">14</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.10367v1" target="_blank" rel="noopener">LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation</a>
        <div class="paper-meta">
          Zhiling Yan, Dingjie Song, Zhe Fang et al.
          &bull; 2026-02-10
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 9/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper addresses critical issues in LLM medical evaluation – contamination and evolving knowledge – with a novel, automated, and rigorous benchmark, promising significant impact on the field&#39;s progress and responsible deployment of these models.</div>
    

    <div class="abstract">The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.10367v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.10367v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">15</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.10177v2" target="_blank" rel="noopener">Towards Autonomous Mathematics Research</a>
        <div class="paper-meta">
          Tony Feng, Trieu H. Trinh, Garrett Bingham et al.
          &bull; 2026-02-10
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 13</span>
      <span class="badge badge-llm-high">
        Impact: 9/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 1</span>
      
      <span class="badge" style="color: var(--green)">Author boost: +3</span>
      
    </div>

    
    <div class="llm-reason">This paper demonstrates a significant leap towards autonomous mathematical research, evidenced by the generation of novel results and collaborative proofs, showcasing high novelty, scope, and potential for broad implications in both AI and mathematics.</div>
    

    <div class="abstract">Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research. We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom&#39;s Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest quantifying standard levels of autonomy and novelty of AI-assisted results, as well as propose a novel concept of human-AI interaction cards for transparency. We conclude with reflections on human-AI collaboration in mathematics and share all prompts as well as model outputs at https://github.com/google-deepmind/superhuman/tree/main/aletheia.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.10177v2" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.10177v2
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">16</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.19534v1" target="_blank" rel="noopener">Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial</a>
        <div class="paper-meta">
          Yousef Emami, Hao Zhou, Radha Reddy et al.
          &bull; 2026-02-23
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This survey paper addresses a highly relevant and emerging intersection of LLMs and UAVs, offering a comprehensive overview and framework that could significantly guide future research and development in the field.</div>
    

    <div class="abstract">Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and context-aware aerial operations. This survey systematically explores the intersection of LLMs and UAV technologies and proposes a unified framework that consolidates existing architectures, methodologies, and applications for UAVs. We first present a structured taxonomy of LLM adaptation techniques for UAVs, including pretraining, fine-tuning, Retrieval-Augmented Generation (RAG), and prompt engineering, along with key reasoning capabilities such as Chain-of-Thought (CoT) and In-Context Learning (ICL). We then examine LLM-assisted UAV communications and operations, covering navigation, mission planning, swarm control, safety, autonomy, and network management. After that, the survey further discusses Multimodal LLMs (MLLMs) for human-swarm interaction, perception-driven navigation, and collaborative control. Finally, we address ethical considerations, including bias, transparency, accountability, and Human-in-the-Loop (HITL) strategies, and outline future research directions. Overall, this work positions LLM-assisted UAVs as a foundation for intelligent and adaptive aerial systems.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.19534v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.19534v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">17</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.17902v1" target="_blank" rel="noopener">El Agente Gráfico: Structured Execution Graphs for Scientific Agents</a>
        <div class="paper-meta">
          Jiaru Bai, Abdulrahman Aldossary, Thomas Swanick et al.
          &bull; 2026-02-19
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a critical challenge in LLM-driven scientific workflows – robustness and auditability – with a novel approach using structured execution graphs and typed objects, demonstrating strong potential for impact in automating complex scientific tasks.</div>
    

    <div class="abstract">Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making within a type-safe execution environment and dynamic knowledge graphs for external persistence. Central to our approach is a structured abstraction of scientific concepts and an object-graph mapper that represents computational state as typed Python objects, stored either in memory or persisted in an external knowledge graph. This design enables context management through typed symbolic identifiers rather than raw text, thereby ensuring consistency, supporting provenance tracking, and enabling efficient tool orchestration. We evaluate the system by developing an automated benchmarking framework across a suite of university-level quantum chemistry tasks previously evaluated on a multi-agent system, demonstrating that a single agent, when coupled to a reliable execution engine, can robustly perform complex, multi-step, and parallel computations. We further extend this paradigm to two other large classes of applications: conformer ensemble generation and metal-organic framework design, where knowledge graphs serve as both memory and reasoning substrates. Together, these results illustrate how abstraction and type safety can provide a scalable foundation for agentic scientific automation beyond prompt-centric designs.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.17902v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.17902v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">18</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.16873v1" target="_blank" rel="noopener">AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence</a>
        <div class="paper-meta">
          Geunbin Yu
          &bull; 2026-02-18
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a timely and important problem – moving beyond model selection to orchestration as LLMs converge – with a rigorous framework, novel algorithms, and strong empirical validation, suggesting significant potential impact on how multi-agent systems are designed and deployed.</div>
    

    <div class="abstract">As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dynamically selects among four canonical topologies (parallel, sequential, hierarchical, and hybrid) based on task dependency graphs and empirically derived domain characteristics. Our framework introduces three key contributions: (1) a Performance Convergence Scaling Law, formalizing conditions under which orchestration selection outweighs model selection; (2) a Topology Routing Algorithm that maps task decomposition DAGs to optimal orchestration patterns in O(|V| + |E|) time; and (3) an Adaptive Synthesis Protocol with provable termination guarantees and heuristic consistency scoring for parallel agent outputs. We validate AdaptOrch across coding (SWE-bench), reasoning (GPQA), and retrieval-augmented generation tasks, demonstrating that topology-aware orchestration achieves 12-23% improvement over static single-topology baselines, even when using identical underlying models. Our results establish orchestration design as a first-class optimization target independent of model scaling.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.16873v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.16873v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">19</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.14612v2" target="_blank" rel="noopener">LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio</a>
        <div class="paper-meta">
          Naveen Vakada, Kartik Hegde, Arvind Krishna Sridhar et al.
          &bull; 2026-02-16
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper addresses a significant challenge in long-form audio processing with a novel and practical approach (LA-RAG) that combines acoustic event detection with RAG, demonstrating strong potential for impact in areas like surveillance, meeting analysis, and accessibility.</div>
    

    <div class="abstract">Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long-audio question answering remains difficult due to context-length limits. We introduce LongAudio-RAG (LA-RAG), a hybrid framework that grounds Large Language Model (LLM) outputs in retrieved, timestamped acoustic event detections rather than raw audio. Multi-hour streams are converted into structured event records stored in an SQL database, and at inference time the system resolves natural-language time references, classifies intent, retrieves only the relevant events, and generates answers using this constrained evidence. To evaluate performance, we construct a synthetic long-audio benchmark by concatenating recordings with preserved timestamps and generating template-based question-answer pairs for detection, counting, and summarization tasks. Finally, we demonstrate the practicality of our approach by deploying it in a hybrid edge-cloud environment, where the audio grounding model runs on-device on IoT-class hardware while the LLM is hosted on a GPU-backed server. This architecture enables low-latency event extraction at the edge and high-quality language reasoning in the cloud. Experiments show that structured, event-level retrieval significantly improves accuracy compared to vanilla Retrieval-Augmented Generation (RAG) or text-to-SQL approaches.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.14612v2" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.14612v2
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">20</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.14160v1" target="_blank" rel="noopener">Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning</a>
        <div class="paper-meta">
          Chaeeun Lee, T. Michael Yates, Pasquale Minervini et al.
          &bull; 2026-02-15
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper addresses a critical gap in LLM-based multi-agent systems by focusing on both outcome accuracy *and* process alignment in a high-stakes clinical reasoning task, demonstrating a novel approach with strong empirical results and clear broader implications for reliable AI in healthcare.</div>
    

    <div class="abstract">Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical real-world case of this is gene-disease validity curation, where experts must determine whether a gene is causally implicated in a disease by synthesising diverse biomedical evidence. We introduce an agent-as-tool reinforcement learning framework for this task with two objectives: (i) process-level supervision to ensure reasoning follows valid clinical pathways, and (ii) efficient coordination via a hierarchical multi-agent system. Our evaluation on the ClinGen dataset shows that with outcome-only rewards, MAS with a GRPO-trained Qwen3-4B supervisor agent substantially improves final outcome accuracy from 0.195 with a base model supervisor to 0.732, but results in poor process alignment (0.392 F1). Conversely, with process + outcome rewards, MAS with GRPO-trained supervisor achieves higher outcome accuracy (0.750) while significantly improving process fidelity to 0.520 F1. Our code is available at https://github.com/chaeeunlee-io/GeneDiseaseCurationAgents.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.14160v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.14160v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">21</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13933v1" target="_blank" rel="noopener">HyMem: Hybrid Memory Architecture with Dynamic Retrieval Scheduling</a>
        <div class="paper-meta">
          Xiaochen Zhao, Kaikai Wang, Xiaowen Zhang et al.
          &bull; 2026-02-15
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a critical limitation of LLM agents – long-term memory – with a novel hybrid architecture and dynamic retrieval, showing strong potential for improving performance and efficiency in complex dialogue scenarios.</div>
    

    <div class="abstract">Large language model (LLM) agents demonstrate strong performance in short-text contexts but often underperform in extended dialogues due to inefficient memory management. Existing approaches face a fundamental trade-off between efficiency and effectiveness: memory compression risks losing critical details required for complex reasoning, while retaining raw text introduces unnecessary computational overhead for simple queries. The crux lies in the limitations of monolithic memory representations and static retrieval mechanisms, which fail to emulate the flexible and proactive memory scheduling capabilities observed in humans, thus struggling to adapt to diverse problem scenarios. Inspired by the principle of cognitive economy, we propose HyMem, a hybrid memory architecture that enables dynamic on-demand scheduling through multi-granular memory representations. HyMem adopts a dual-granular storage scheme paired with a dynamic two-tier retrieval system: a lightweight module constructs summary-level context for efficient response generation, while an LLM-based deep module is selectively activated only for complex queries, augmented by a reflection mechanism for iterative reasoning refinement. Experiments show that HyMem achieves strong performance on both the LOCOMO and LongMemEval benchmarks, outperforming full-context while reducing computational cost by 92.6\%, establishing a state-of-the-art balance between efficiency and performance in long-term memory management.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13933v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13933v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">22</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13647v1" target="_blank" rel="noopener">PT-RAG: Structure-Fidelity Retrieval-Augmented Generation for Academic Papers</a>
        <div class="paper-meta">
          Rui Yu, Tianyi Wang, Ruixia Liu et al.
          &bull; 2026-02-14
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">The paper addresses a significant problem in RAG for academic papers – preserving document structure – with a novel approach (PaperTree index and path-guided retrieval) that has the potential to improve performance and efficiency, and the focus on low-entropy retrieval is a strong methodological contribution.</div>
    

    <div class="abstract">Retrieval-augmented generation (RAG) is increasingly applied to question-answering over long academic papers, where accurate evidence allocation under a fixed token budget is critical. Existing approaches typically flatten academic papers into unstructured chunks during preprocessing, which destroys the native hierarchical structure. This loss forces retrieval to operate in a disordered space, thereby producing fragmented contexts, misallocating tokens to non-evidential regions under finite token budgets, and increasing the reasoning burden for downstream language models. To address these issues, we propose PT-RAG, an RAG framework that treats the native hierarchical structure of academic papers as a low-entropy retrieval prior. PT-RAG first inherits the native hierarchy to construct a structure-fidelity PaperTree index, which prevents entropy increase at the source. It then designs a path-guided retrieval mechanism that aligns query semantics to relevant sections and selects high relevance root-to-leaf paths under a fixed token budget, yielding compact, coherent, and low-entropy retrieval contexts. In contrast to existing RAG approaches, PT-RAG avoids entropy increase caused by destructive preprocessing and provides a native low-entropy structural basis for subsequent retrieval. To assess this design, we introduce entropy-based structural diagnostics that quantify retrieval fragmentation and evidence allocation accuracy. On three academic question-answering benchmarks, PT-RAG achieves consistently lower section entropy and evidence alignment cross entropy than strong baselines, indicating reduced context fragmentation and more precise allocation to evidential regions. These structural advantages directly translate into higher answer quality.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13647v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13647v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">23</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13571v1" target="_blank" rel="noopener">LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems</a>
        <div class="paper-meta">
          Zhipeng Song, Xiangyu Kong, Xinrui Bao et al.
          &bull; 2026-02-14
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper presents a novel, training-free reranking method leveraging LLM confidence scores, addressing a key challenge in RAG systems with strong empirical results on standard benchmarks, suggesting significant potential impact.</div>
    

    <div class="abstract">Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval and ranking. Although existing rerankers demonstrate effectiveness, they frequently necessitate specialized training, impose substantial computational expenses, and fail to fully exploit the semantic capabilities of LLMs, particularly their inherent confidence signals. We propose the LLM-Confidence Reranker (LCR), a training-free, plug-and-play algorithm that enhances reranking in RAG systems by leveraging black-box LLM confidence derived from Maximum Semantic Cluster Proportion (MSCP). LCR employs a two-stage process: confidence assessment via multinomial sampling and clustering, followed by binning and multi-level sorting based on query and document confidence thresholds. This approach prioritizes relevant documents while preserving original rankings for high-confidence queries, ensuring robustness. Evaluated on BEIR and TREC benchmarks with BM25 and Contriever retrievers, LCR--using only 7--9B-parameter pre-trained LLMs--consistently improves NDCG@5 by up to 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, without degradation. Ablation studies validate the hypothesis that LLM confidence positively correlates with document relevance, elucidating LCR&#39;s mechanism. LCR offers computational efficiency, parallelism for scalability, and broad compatibility, mitigating hallucinations in applications like medical diagnosis.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13571v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13571v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">24</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.13562v1" target="_blank" rel="noopener">Mitigating the Safety-utility Trade-off in LLM Alignment via Adaptive Safe Context Learning</a>
        <div class="paper-meta">
          Yanbo Wang, Minzheng Wang, Jian Liang et al.
          &bull; 2026-02-14
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">This paper addresses a critical challenge in LLM alignment – the safety-utility trade-off – with a novel framework (ASCL) and a clever optimization technique (IFPO), showing strong potential for improving both safety and reasoning capabilities.</div>
    

    <div class="abstract">While reasoning models have achieved remarkable success in complex reasoning tasks, their increasing power necessitates stringent safety measures. For safety alignment, the core challenge lies in the inherent trade-off between safety and utility. However, prevailing alignment strategies typically construct CoT training data with explicit safety rules via context distillation. This approach inadvertently limits reasoning capabilities by creating a rigid association between rule memorization and refusal. To mitigate the safety-utility trade-off, we propose the Adaptive Safe Context Learning (ASCL) framework to improve the reasoning given proper context. ASCL formulates safety alignment as a multi-turn tool-use process, empowering the model to autonomously decide when to consult safety rules and how to generate the ongoing reasoning. Furthermore, to counteract the preference for rule consultation during RL, we introduce Inverse Frequency Policy Optimization (IFPO) to rebalance advantage estimates. By decoupling rule retrieval and subsequent reasoning, our method achieves higher overall performance compared to baselines.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.13562v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.13562v1
    </a>
  </div>
  
  
  <div class="paper">
    <div class="paper-header">
      <div class="rank">25</div>
      <div class="paper-title">
        <a href="https://arxiv.org/abs/2602.18493v1" target="_blank" rel="noopener">Learning to Remember: End-to-End Training of Memory Agents for Long-Context Reasoning</a>
        <div class="paper-meta">
          Kehao Zhang, Shangtong Gui, Sheng Yang et al.
          &bull; 2026-02-13
        </div>
      </div>
    </div>

    <div class="scores">
      <span class="badge badge-final">Final: 12</span>
      <span class="badge badge-llm-high">
        Impact: 8/10
      </span>
      <span class="badge" style="color: var(--muted)">Keywords: 4</span>
      
    </div>

    
    <div class="llm-reason">The paper presents a novel end-to-end learning framework for memory agents with a strong focus on dynamic reasoning and a new benchmark, demonstrating significant improvements over existing methods and suggesting broader implications for handling long-context information.</div>
    

    <div class="abstract">Long-context LLMs and Retrieval-Augmented Generation (RAG) systems process information passively, deferring state tracking, contradiction resolution, and evidence aggregation to query time, which becomes brittle under ultra long streams with frequent updates. We propose the Unified Memory Agent (UMA), an end-to-end reinforcement learning framework that unifies memory operations and question answering within a single policy. UMA maintains a dual memory representation: a compact core summary for global context and a structured Memory Bank that supports explicit CRUD (create, update, delete, reorganize) over key value entries, enabling proactive consolidation during streaming. To evaluate long-horizon memory behavior, we introduce Ledger-QA, a diagnostic benchmark for continuous state tracking where answers are latent values derived from accumulated updates rather than lo cal span retrieval. Across 13 datasets spanning Ledger-QA, Test-Time Learning, and Accurate Retrieval, UMA substantially outperforms long-context and RAG baselines on dynamic reasoning and learning tasks while remaining competitive on standard retrieval benchmarks, underscoring the importance of learned, end-to-end memory management.</div>

    <a class="arxiv-link" href="https://arxiv.org/abs/2602.18493v1" target="_blank" rel="noopener">
      arXiv: https://arxiv.org/abs/2602.18493v1
    </a>
  </div>
  

  <footer>
    Apollo &mdash; Biweekly CS/AI Research Digest &bull;
    Powered by <a href="https://github.com/zeroclaw-labs/zeroclaw">ZeroClaw</a> &amp;
    <a href="https://gemini.google.com/">Gemini</a>
  </footer>

</div>
</body>
</html>